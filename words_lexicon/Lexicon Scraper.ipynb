{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('words', 'r')\n",
    "word_list = []\n",
    "pos_dict  = {}\n",
    "for word in words:\n",
    "    word = word.strip().lower()\n",
    "    word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = \"https://www.wordsmyth.net/\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_list:\n",
    "    elem = driver.find_element_by_class_name(\"search_form\")\n",
    "    search = elem.find_element_by_css_selector(\"input\")\n",
    "    search.clear()\n",
    "    search.send_keys(word)\n",
    "    search.send_keys(Keys.RETURN)\n",
    "    part_of_speech = driver.find_elements_by_class_name(\"postitle\")\n",
    "    if part_of_speech:\n",
    "        for ele in part_of_speech:\n",
    "            key =  ele.find_element_by_class_name(\"data\").text\n",
    "            if key in pos_dict:\n",
    "                pos_dict[key].add(word)\n",
    "            else:\n",
    "                pos_dict[key]=set([word])\n",
    "    else:\n",
    "        words = driver.find_element_by_class_name(\"wordlist\")\n",
    "        links = words.find_elements_by_partial_link_text('')\n",
    "        link_lis = []\n",
    "        for link in links:\n",
    "            link_lis.append(link.get_attribute(\"href\"))\n",
    "        for link in link_lis:\n",
    "            driver.get(link)\n",
    "            part_of_speech = driver.find_elements_by_class_name(\"postitle\")\n",
    "            for ele in part_of_speech:\n",
    "                key =  ele.find_element_by_class_name(\"data\").text\n",
    "                if key in pos_dict:\n",
    "                    pos_dict[key].add(word)\n",
    "                else:\n",
    "                    pos_dict[key]=set([word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('lexicon.txt', 'w+')\n",
    "for key in pos_dict:\n",
    "    file.write(str(key.upper() + \"\\n\"))\n",
    "    file.write(str(str(pos_dict[key])+ \"\\n\"))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos_dict = {}\n",
    "file = open('lexicon.txt', 'r')\n",
    "for line in file:\n",
    "    pos = line.strip()\n",
    "    lis = file.readline().strip()[2:-2]\n",
    "    new_pos_dict[pos] = set(lis.split('\\', \\''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABBREVIATION\n",
      "NOUN\n",
      "ADJECTIVE\n",
      "INDEFINITE ARTICLE\n",
      "PREPOSITION\n",
      "PREFIX\n",
      "SUFFIX\n",
      "ADVERB\n",
      "TRANSITIVE VERB\n",
      "INTRANSITIVE VERB\n",
      "CONJUNCTION\n",
      "PRONOUN\n",
      "TRANSITIVE VERB & INTRANSITIVE VERB\n",
      "AUXILIARY VERB\n",
      "INTERJECTION\n",
      "VERB\n",
      "PHRASE\n",
      "CONTRACTION\n",
      "PLURAL NOUN\n",
      "NOUN & ABBREVIATION\n",
      "ADJECTIVE & ADVERB\n",
      "DEFINITE ARTICLE\n",
      "PLURAL PRONOUN\n",
      "ADJECTIVE & PRONOUN\n",
      "ADJECTIVE & ADVERB & PREPOSITION\n"
     ]
    }
   ],
   "source": [
    "for key in new_pos_dict.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase(pos_dict):\n",
    "    noun1 = random.choice(list(new_pos_dict[\"NOUN\"])) \n",
    "    prep1 = random.choice(list(new_pos_dict[\"PREPOSITION\"]))\n",
    "    noun2 = random.choice(list(new_pos_dict[\"NOUN\"]))\n",
    "    return (noun1 + \" \" + prep1 + \" \" + noun2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital after ground\n",
      "choice from wall\n",
      "health onto international\n",
      "behind from century\n",
      "house until analysis\n",
      "oil a blue\n",
      "try without computer\n",
      "class as mission\n",
      "station before response\n",
      "rock during skill\n",
      "once before then\n",
      "kitchen but deal\n",
      "second before decade\n",
      "on past catch\n",
      "interesting by hundred\n",
      "author toward act\n",
      "choice per while\n",
      "interesting up like\n",
      "number into difference\n",
      "if across what\n",
      "care toward purpose\n",
      "cancer until his\n",
      "sport about car\n",
      "start down war\n",
      "body by present\n",
      "professional toward research\n",
      "hair through pattern\n",
      "boy outside smile\n",
      "tree into weight\n",
      "patient until fine\n",
      "environmental since green\n",
      "agency a fail\n",
      "eight outside wind\n",
      "position onto me\n",
      "term across cover\n",
      "private around light\n",
      "coach without owner\n",
      "range above push\n",
      "step for student\n",
      "go save mind\n",
      "choice like get\n",
      "fund despite age\n",
      "heart save our\n",
      "mother down opportunity\n",
      "cancer above culture\n",
      "compare across director\n",
      "cause in close\n",
      "country behind century\n",
      "government along long\n",
      "bank about note\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    print(phrase(new_pos_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrapy",
   "language": "python",
   "name": "scrapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
